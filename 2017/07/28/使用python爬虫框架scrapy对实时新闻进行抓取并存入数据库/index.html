<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">






  
  
  <link rel="stylesheet" media="all" href="/lib/Han/dist/han.min.css?v=3.3">




<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/w.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/w.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/w.png?v=5.1.3">


  <link rel="mask-icon" href="/images/w.png?v=5.1.3" color="#222">





  <meta name="keywords" content="python，scrapy，mysql，新闻抓取," />





  <link rel="alternate" href="/atom.xml" title="whtis's blog" type="application/atom+xml" />






<meta name="description" content="写在前面每天的新闻更新很快，如果要全面了解非常困难，更可恶的是一些门户网站还经常取一些乱七八糟的标题，点进去是文不对题。所以萌生了一个想法：自己抓取不同门户网站的新闻更新信息，然后将这些内容进行整合，推送一些当日的热点新闻。想的很简单，真的做起来，发现自己还是太年轻，到写这篇博客为止，我也就是完成了一个基本的抓取框架，连内容都没有获得多少。不过本来就是抱着学习python的想法使用scrapy来抓">
<meta name="keywords" content="python，scrapy，mysql，新闻抓取">
<meta property="og:type" content="article">
<meta property="og:title" content="使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库">
<meta property="og:url" content="whtis.github.io/2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/index.html">
<meta property="og:site_name" content="whtis&#39;s blog">
<meta property="og:description" content="写在前面每天的新闻更新很快，如果要全面了解非常困难，更可恶的是一些门户网站还经常取一些乱七八糟的标题，点进去是文不对题。所以萌生了一个想法：自己抓取不同门户网站的新闻更新信息，然后将这些内容进行整合，推送一些当日的热点新闻。想的很简单，真的做起来，发现自己还是太年轻，到写这篇博客为止，我也就是完成了一个基本的抓取框架，连内容都没有获得多少。不过本来就是抱着学习python的想法使用scrapy来抓">
<meta property="og:updated_time" content="2017-07-29T06:36:53.372Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库">
<meta name="twitter:description" content="写在前面每天的新闻更新很快，如果要全面了解非常困难，更可恶的是一些门户网站还经常取一些乱七八糟的标题，点进去是文不对题。所以萌生了一个想法：自己抓取不同门户网站的新闻更新信息，然后将这些内容进行整合，推送一些当日的热点新闻。想的很简单，真的做起来，发现自己还是太年轻，到写这篇博客为止，我也就是完成了一个基本的抓取框架，连内容都没有获得多少。不过本来就是抱着学习python的想法使用scrapy来抓">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="whtis.github.io/2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/"/>





  <title>使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库 | whtis's blog</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-69300841-1', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?9cb4437eed6d232c3aaf406d3f6fbfda";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">whtis's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-guestbook">
          <a href="/guestbook/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-pencil"></i> <br />
            
            留言板
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-xin">
          <a href="/xin/love" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            爱馨馨
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'u2DWQSSegALVDFRKBsKh','2.0.0');
</script>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="whtis.github.io/2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="whtis">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/whtis.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whtis's blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-28T22:15:20+08:00">
                2017-07-28
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2017-07-29T14:36:53+08:00">
                2017-07-29
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,847
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  11
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h3 id="写在前面">写在前面</h3><p>每天的新闻更新很快，如果要全面了解非常困难，更可恶的是一些门户网站还经常取一些乱七八糟的标题，点进去是文不对题。所以萌生了一个想法：自己抓取不同门户网站的新闻更新信息，然后将这些内容进行整合，推送一些当日的热点新闻。<br>想的很简单，真的做起来，发现自己还是太年轻，到写这篇博客为止，我也就是完成了一个基本的抓取框架，连内容都没有获得多少。不过本来就是抱着学习<code>python</code>的想法使用<code>scrapy</code>来抓取新闻，既然已经有了个差不多的框架，也该写写使用<code>scrapy</code>过程中的遇到的一些问题了。</p>
<h3 id="明确需求和技术路线">明确需求和技术路线</h3><ul>
<li>需求：很简单，抓取每天最新的新闻内容（文本），按照一定的格式存入数据库<code>mysql</code>中。</li>
<li>技术路线：之前一直在使用<code>java</code>语言开发的<code>webmagic</code>开源爬虫框架进行爬虫开发。但一直听说<code>python</code>下有个大名鼎鼎的爬虫框架<code>scrapy</code>,所以抱着学习的态度，使用<code>scrapy</code>进行爬虫的开发。</li>
</ul>
<h3 id="简单的技术介绍和入门">简单的技术介绍和入门</h3><p>之前只是使用<code>python</code>写过一些简单的脚本，这次为了使用<code>scrapy</code>,看了一遍<strong>廖雪峰大大</strong>的<code>python3</code><a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="external">教程</a><br>看完后没记住多少，不过有个概念就是了。然后开始查看一些讲<code>scrapy</code>入门的博客，自己实现博客中的例子，算是对<code>scrapy</code>有个大概的了解。我复现的例子是这个：<a href="http://www.jianshu.com/p/fa614bea98eb" target="_blank" rel="external">【图文详解】scrapy安装与真的快速上手——爬取豆瓣9分榜单</a></p>
<h3 id="需求的再分析及让scrapy与需求相关">需求的再分析及让<code>scrapy</code>与需求相关</h3><ul>
<li>需求分析：新闻内容很多，获取的方式也不同。最笨的方式就是复现浏览器的行为：针对不同的信息源获取不同的页面进行解析；其次好一点的方法：由于某些新闻网站提供了rss订阅接口，因此可以解析此接口页面获得内容。下面分析下这两种方法的优缺点：<ul>
<li>模拟浏览器行为：<ul>
<li>优点：能够精准解析到需要的内容</li>
<li>缺点：解析难度高，主流新闻网站都有一系列反爬虫机制；代码与页面结构高度相关，如页面改版，代码改动较大</li>
</ul>
</li>
<li>rss接口：<ul>
<li>优点：不同网站的接口页面结构基本相同，可以使用一套解析逻辑进行解析</li>
<li>缺点：并不是所有网站都会提供该接口，且该接口返回的数据，有些仅有正文摘要，还需要再进一次网站获取完整的正文内容</li>
</ul>
</li>
</ul>
</li>
<li>明确需求下的<code>scrapy</code>:上一节提到的入门内容如果看完后，应该对<code>scrapy</code>会有一个大概的整体认识。在我这需求下，似乎单独创建一个爬虫无法完成所有的需求。因此我创建了两个爬虫文件：<code>rss_news_spider.py</code>和<code>web_news_spider.py</code>，下面会对这两个文件进行详细解释。</li>
</ul>
<h3 id="开始写爬虫">开始写爬虫</h3><h4 id="使用scrapy基础模板来爬取rss接口的新闻内容">使用scrapy基础模板来爬取rss接口的新闻内容</h4><p>终于，振奋人心的时刻到了。可以开始我们的爬虫了。首先我们创建<code>runRss.py</code>,然后写上如下启动爬虫的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="comment"># run rssSpider</span></div><div class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</div><div class="line"></div><div class="line">cmdline.execute(<span class="string">"scrapy crawl rss"</span>.split())</div></pre></td></tr></table></figure>
<p>是不是很熟悉，对，这条命令启动了名为<code>rss</code>的爬虫（<strong>注意，在scrapy中创建的每一个爬虫必须有自己唯一的<code>name</code>，否则无法启动</strong>）。我的<code>rss</code>爬虫位于<code>rss_news_spider.py</code>这个文件当中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RssSpider</span><span class="params">(scrapy.Spider)</span>:</span></div><div class="line">    name = <span class="string">'rss'</span></div><div class="line">    start_urls = [</div><div class="line">        <span class="string">'http://www.wyzxwk.com/e/web/?type=rss2&amp;classid=0'</span>,</div><div class="line">    ]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></div><div class="line">        <span class="keyword">if</span> response.url.find(<span class="string">'rss'</span>) != <span class="number">-1</span>:</div><div class="line">            <span class="keyword">yield</span> Request(response.url, callback=self.parse_rss)</div><div class="line">        <span class="keyword">elif</span> response.url.find(<span class="string">'Article'</span>) != <span class="number">-1</span>:</div><div class="line">            <span class="keyword">yield</span> Request(response.url, callback=self.parse_details)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            self.logger.info(<span class="string">'start urls is not useful, please check it!'</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_rss</span><span class="params">(self, response)</span>:</span></div><div class="line">        selector = scrapy.Selector(response)</div><div class="line">        contents = selector.xpath(<span class="string">'//channel/item'</span>)</div><div class="line">        <span class="keyword">for</span> content <span class="keyword">in</span> contents:</div><div class="line">            title = content.xpath(<span class="string">'title/text()'</span>).extract()[<span class="number">0</span>]</div><div class="line">            link = content.xpath(<span class="string">'link/text()'</span>).extract()[<span class="number">0</span>]</div><div class="line">            ……</div><div class="line">            article = ArticleItem()</div><div class="line">            article[<span class="string">'table_name'</span>] = <span class="string">'article_'</span> + table_name.lower()</div><div class="line">            article[<span class="string">'title'</span>] = title</div><div class="line">            article[<span class="string">'url'</span>] = link</div><div class="line">            <span class="keyword">if</span> link <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">                <span class="keyword">yield</span> scrapy.http.Request(url=link, meta=&#123;<span class="string">'item'</span>: article&#125;, callback=self.parse_details)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_details</span><span class="params">(self, response)</span>:</span></div><div class="line">        article = response.meta[<span class="string">'item'</span>]</div><div class="line">        selector = scrapy.Selector(response)</div><div class="line">        content = selector.xpath(<span class="string">'//div[@class="m-article s-shadow"]/article/p'</span>).extract().__str__()</div><div class="line">        content = content.replace(<span class="string">"', '"</span>, <span class="string">""</span>).replace(<span class="string">"\\u3000"</span>, <span class="string">"  "</span>).replace(<span class="string">"'"</span>, <span class="string">""</span>).replace(<span class="string">"\\xa0"</span>, <span class="string">""</span>)</div><div class="line">            .replace(<span class="string">"▍"</span>, <span class="string">""</span>)</div><div class="line">        article[<span class="string">'content'</span>] = content</div><div class="line">        <span class="keyword">return</span> article</div></pre></td></tr></table></figure></p>
<p>来认真看下这段代码：</p>
<ul>
<li>设置<code>name</code>、<code>start_urls</code>和<code>parse</code>函数我们都很熟悉。那<code>parse_rss</code>和<code>parse_details</code>是干嘛用的？<ul>
<li>在本文的例子中，我们用了<a href="http://www.wyzxwk.com/" target="_blank" rel="external">乌有之乡</a>的<code>rss</code>接口作为例子。这个<code>rss</code>接口的特点是给出的正文内容是 摘要，如果要查看详细的正文内容需要访问相应的<code>url</code>,因此两个函数的作用就非常明显了：<code>parse_rss</code>函数是处理接口页面的信息并获取正文的链接，然后使用<code>parse_details</code>函数对正文做解析。</li>
<li>这个地方比较重要的是函数之间如何传递参数？也就是我想把<code>parse_rss</code>中解析到的内容传递给<code>parse_details</code>。从代码中可以看出，我们在传递链接的时候使用的<code>scrapy.http.Request</code>中可以附加参数：<code>url</code>是链接；<code>meta</code>是一个字典，可以包含所有希望下一个函数获得的内容；<code>callback</code>是回调函数，用于指定这些内容由哪个函数进行处理。</li>
</ul>
</li>
<li><code>start_urls</code>中注释的url是干啥用的？<ul>
<li>如我们在需求分析中所说，rss接口页面结构是相同的，因此理论上来说，在<code>parse_details</code>之前的逻辑，适用于任何实现了rss接口的网站。</li>
</ul>
</li>
</ul>
<p>现在有个问题？如果我爬取的网站比较多，那么<code>parse_details</code>的逻辑我是不是要根据不同的网站去分别实现？按道理来说是这样的，但<code>scrapy</code>还为我们提供了另外一种实现思路。下面的内容主要参考了如下几篇博客：</p>
<ul>
<li><a href="http://www.code123.cc/1431.html" target="_blank" rel="external">Python爬虫框架Scrapy教程(1)—入门</a></li>
<li><a href="http://www.code123.cc/1432.html" target="_blank" rel="external">Python爬虫框架Scrapy教程(2)—动态可配置</a></li>
<li><a href="http://www.code123.cc/1434.html" target="_blank" rel="external">Python爬虫框架Scrapy教程(3)—使用Redis和SQLAlchemy</a></li>
</ul>
<h4 id="读取数据库配置动态生成爬虫">读取数据库配置动态生成爬虫</h4><p>我们知道，爬虫的核心其实就是发送请求与接收请求。那么如果我们要从网络上获取到新闻内容，浏览器发送这两个请求就可以：<br>1、请求新闻的列表页，解析出每一篇新闻的详细链接<br>2、访问每一篇新闻的详细链接，然后解析返回的内容，就可以得到新闻的标题、发表时间、正文等内容了。<br>（<strong>以上两步其实是爬虫领域很经典的列表+详情页爬取逻辑</strong>）<br>在这个过程中，浏览器（或者代码）的执行步骤是相同的，不同的只是访问的链接，以及对不同链接内容的解析（主要是<code>xpath</code>和<code>正则表达式</code>）。因此假设访问的链接和解析方法都能够动态加载（从数据库中读取），那么我们就可以写一个爬虫来加载这些配置，实现多个网站内容的抓取了。<br>我们创建一个<code>runWeb.py</code>文件，写入下面内容：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># run webSpider</span></div><div class="line">settings = Settings()</div><div class="line">settings.set(<span class="string">"ITEM_PIPELINES"</span>, &#123;</div><div class="line">    <span class="comment"># 'pipelines.DuplicatesPipeline': 200,</span></div><div class="line">    <span class="comment"># 'pipelines.CountDropPipline': 100,</span></div><div class="line">    <span class="string">'pipelines.DataBasePipeline'</span>: <span class="number">300</span>,</div><div class="line">&#125;)</div><div class="line"><span class="comment"># crawl settings</span></div><div class="line">settings.set(<span class="string">"USER_AGENT"</span>,</div><div class="line">             <span class="string">"Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari"</span></div><div class="line">             <span class="string">"/537.36"</span>)</div><div class="line"></div><div class="line">process = CrawlerProcess(settings)</div><div class="line"></div><div class="line">db = DBSession()</div><div class="line">rules = db.query(Rule).filter(Rule.enable == <span class="number">1</span>)</div><div class="line"><span class="keyword">for</span> rule <span class="keyword">in</span> rules:</div><div class="line">    process.crawl(WebSpider, rule)</div><div class="line">process.start()</div></pre></td></tr></table></figure></p>
<p>加载完自定义<code>settings</code>后，对每一个<code>rule</code>生成一个进程，运行<code>webSpider</code>。我的<code>webSpider</code>在<code>web_news_spider</code>中。可以看下这里面的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">WebSpider</span><span class="params">(CrawlSpider)</span>:</span></div><div class="line">    name = <span class="string">"web"</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, rule)</span>:</span></div><div class="line">        self.rule = rule</div><div class="line">        self.name = rule.site_name</div><div class="line">        self.allowed_domains = rule.allow_domains.split(<span class="string">","</span>)</div><div class="line">        self.start_urls = rule.start_urls.split(<span class="string">","</span>)</div><div class="line">        rule_list = []</div><div class="line">        <span class="comment"># 添加`下一页`的规则</span></div><div class="line">        <span class="keyword">if</span> rule.next_page:</div><div class="line">            rule_list.append(Rule(LinkExtractor(restrict_xpaths=rule.next_page)))</div><div class="line">        <span class="comment"># 添加抽取文章链接的规则</span></div><div class="line">        rule_list.append(Rule(LinkExtractor(</div><div class="line">            allow=[rule.allow_url],</div><div class="line">            restrict_xpaths=[rule.extract_from]),</div><div class="line">            callback=<span class="string">'parse_item'</span>, follow=<span class="keyword">True</span>))</div><div class="line">        self.rules = tuple(rule_list)</div><div class="line">        super(WebSpider, self).__init__()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></div><div class="line">        self.log(<span class="string">'Hi, this is a web page! %s'</span> % response.url)</div><div class="line"></div><div class="line">        content = infos.xpath(self.rule.content_xpath).extract()</div><div class="line">        article[<span class="string">"content"</span>] = content[<span class="number">0</span>] <span class="keyword">if</span> content <span class="keyword">else</span> <span class="string">""</span></div><div class="line"></div><div class="line">        publish_time = infos.xpath(self.rule.publish_time_xpath).extract()</div><div class="line">        article[<span class="string">"publish_time"</span>] = publish_time[<span class="number">0</span>] <span class="keyword">if</span> publish_time <span class="keyword">else</span> <span class="string">""</span></div><div class="line">        ……</div></pre></td></tr></table></figure></p>
<p>其中<code>__init__</code>函数很关键，除了从数据库读取配置外，它使用<code>Rule(LinkExtractor(……))</code>指定了对新闻列表页的解析规则：<code>allow</code>指定了加入下载队列中url的格式；<code>restrict_xpaths</code>指定了寻找url的页面范围;<code>callback</code>指定了处理后续url（新闻详情页）的方法。</p>
<ul>
<li><code>allow</code>和<code>restrict_xpaths</code>从<code>正则表达式</code>和<code>xpath</code>共同对后续帖子详情页url进行限制；</li>
<li><code>callback</code>指定的是解析详情页的方法，顾名思义，列表页的处理是由爬虫自己处理的（使用参数，这也是我没搞懂的地方，因为不是自己处理，在爬虫无法抽取详情页url时很难定位到哪里出错了）</li>
</ul>
<p>如果你的<code>allow</code>和<code>restrict_xpaths</code>设置无误，且列表页返回的信息很完整，你就可以使用<code>parse_item</code>函数制定解析详情页的逻辑了。<br><strong>1、初始接触这种方法时，极其建议使用已经有的例子进行学习，上面提到的博客中的代码，在本文书写时仍能正常运行</strong><br><strong>2、这种方法对动态加载的列表页是无效的</strong></p>
<h3 id="把抓取到的内容存入数据库">把抓取到的内容存入数据库</h3><p>网上大部分使用的<code>mysql</code>驱动是<code>mysqlDb</code>，但是它不支持<code>python3.x</code>。因此本文使用的是<code>pymysql</code>,<code>orm</code>框架是<a href="https://www.sqlalchemy.org/" target="_blank" rel="external"><code>SQLAlchemy</code></a><br>本文仅对一些缺少资料地方进行说明：</p>
<ul>
<li><code>SQLAlchemy</code>连接数据库的方法（参考自官方文档）：<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 初始化数据库连接:</span></div><div class="line">engine = create_engine(<span class="string">'mysql+pymysql://user:passwd@localhost:3306/spider?charset=utf8mb4'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 创建DBSession类型:</span></div><div class="line">DBSession = sessionmaker(bind=engine)</div></pre></td></tr></table></figure>
</li>
</ul>
<p>需要注意的是，初始化<code>engine</code>时需要指定数据库。本文使用的代码，数据库信息存储在<code>scrapy</code>的默认<code>settings</code>中。</p>
<ul>
<li>SQLAlchemy存储信息时动态指定表名<br>我们有这个一个需求，不同的网站内容我们需要存储到不同的表当中。但学习<code>SQLAlchemy</code>用法的时候，我们可以看到，在创建<code>model</code>类时就必须指定<code>__tablename__</code>,否则无法存储。<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArticleModel</span><span class="params">(Base)</span>:</span></div><div class="line">    __tablename__ = <span class="string">'none'</span></div><div class="line"></div><div class="line">    aid = Column(Integer, primary_key=<span class="keyword">True</span>)</div><div class="line">    title = Column(String)</div><div class="line">    url = Column(String)</div><div class="line">    ……</div></pre></td></tr></table></figure>
</li>
</ul>
<p>那我们总不能创建多个除了<code>__tablename__</code>不同其他都相同的<code>modle</code>类吧。还好，我们可以使用如下方法在向数据库插入数据的时候（pipeline中）动态指定表名：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ArticleModel.__table__.name = item[<span class="string">'table_name'</span>]</div><div class="line">a = ArticleModel(title=item[<span class="string">"title"</span>].encode(<span class="string">"utf-8"</span>),</div><div class="line">                 url=item[<span class="string">"url"</span>],</div><div class="line">                 ……</div><div class="line">                ）</div></pre></td></tr></table></figure></p>
<h3 id="其他">其他</h3><p>本来以为<code>mysql</code>中的<code>timestamp</code>对应于<code>python</code>中的<code>date</code>类型，今天向数据库中插入时间戳的时候，才发现对应的是<code>str</code>类型。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pub_float = time.mktime(time.strptime(pubDate, <span class="string">'%a, %d %b %Y %X %z'</span>))</div><div class="line">timestamp = time.strftime(<span class="string">'%Y-%m-%d %X'</span>, time.localtime(pub_float))</div></pre></td></tr></table></figure></p>
<blockquote>
<blockquote>
<blockquote>
<p>type(timestamp) → str</p>
</blockquote>
</blockquote>
</blockquote>
<h3 id="后记">后记</h3><p>本文所写内容为这段时间学习成果之记录，开头所提到的需求离实际完成还很远。文中提到的第二种方法在具体到本文中需求中使用时并没有成功，具体原因由于本人水平所限，并未查出来。如果有对这方面感兴趣的可以一同研究学习。本文提到的完整代码可以在我的<a href="https://github.com/whtis/news_scrapy" target="_blank" rel="external">github</a>上找到。</p>
<hr>
<div align="center" style="color:red;width=80px;height:90px;" onmouseout="this.style.border='1px solid blue'" onmouseover="this.style.border='none'"><br><p style="font-weight:bold;font-style:italic;">本文章首发<a href="http://www.whtis.com" target="_blank" rel="external">www.whtis.com</a>，转载请注明出处</p><br></div>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>如果觉得这篇文章还有用的话，请我喝杯饮料呗~~</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="http://7xnttb.com1.z0.glb.clouddn.com/mm_facetoface_collect_qrcode_1471188145871.png" alt="whtis 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="http://7xnttb.com1.z0.glb.clouddn.com/zhufubao_qcode.jpg" alt="whtis 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    whtis
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="whtis.github.io/2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/" title="使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库">whtis.github.io/2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python，scrapy，mysql，新闻抓取/" rel="tag"><i class="fa fa-tag"></i> python，scrapy，mysql，新闻抓取</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div id="needsharebutton-postbottom">
            <span class="btn">
              <i class="fa fa-share-alt" aria-hidden="true"></i>
            </span>
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/06/19/使用ubuntu过程中的一些命令集合/" rel="next" title="使用ubuntu过程中的一些命令集合">
                <i class="fa fa-chevron-left"></i> 使用ubuntu过程中的一些命令集合
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/10/06/spring4学习笔记（一）--spring 简介/" rel="prev" title="spring4 学习笔记（一）--spring 简介">
                spring4 学习笔记（一）--spring 简介 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/whtis.jpg"
                alt="whtis" />
            
              <p class="site-author-name" itemprop="name">whtis</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">48</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/whtis" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://weibo.com/whtis" target="_blank" title="Weibo">
                    
                      <i class="fa fa-fw fa-weibo"></i></a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:whtisw@gmail.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i></a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#写在前面"><span class="nav-number">1.</span> <span class="nav-text">写在前面</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#明确需求和技术路线"><span class="nav-number">2.</span> <span class="nav-text">明确需求和技术路线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简单的技术介绍和入门"><span class="nav-number">3.</span> <span class="nav-text">简单的技术介绍和入门</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#需求的再分析及让scrapy与需求相关"><span class="nav-number">4.</span> <span class="nav-text">需求的再分析及让scrapy与需求相关</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#开始写爬虫"><span class="nav-number">5.</span> <span class="nav-text">开始写爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用scrapy基础模板来爬取rss接口的新闻内容"><span class="nav-number">5.1.</span> <span class="nav-text">使用scrapy基础模板来爬取rss接口的新闻内容</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#读取数据库配置动态生成爬虫"><span class="nav-number">5.2.</span> <span class="nav-text">读取数据库配置动态生成爬虫</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#把抓取到的内容存入数据库"><span class="nav-number">6.</span> <span class="nav-text">把抓取到的内容存入数据库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#其他"><span class="nav-number">7.</span> <span class="nav-text">其他</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#后记"><span class="nav-number">8.</span> <span class="nav-text">后记</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">whtis</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">60.0k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  





  
  



  
  





  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_sphere.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  

    
      <script id="dsq-count-scr" src="https://whtis.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'whtis.github.io/2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/';
          this.page.identifier = '2017/07/28/使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库/';
          this.page.title = '使用python爬虫框架scrapy对实时新闻进行抓取并存入数据库';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://whtis.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  


















  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
